#Envoy acts as an edge proxy (ingress) for your cluster, fronting httpbin and nginx.

#create backends.yaml

#create services.yaml
#No NodePort yet; Envoy will be the ingress.

#create envoy-config.yaml

#create envoy-deployment.yaml
#Edge proxy deployment

#create envoy-service.yaml
#Expose envoy to external clients

#Deployment
kubectl apply -f backends.yaml
kubectl apply -f services.yaml
kubectl apply -f envoy-config.yaml
kubectl apply -f envoy-deployment.yaml
kubectl apply -f envoy-service.yaml

#or RUN
kubectl apply -f final-deployment.yaml

#check
kubectl get pods
kubectl get svc

kubectl get pods -o wide
--check the IP of envoy

#Test routing through Envoy
kubectl get node -o wide
NAME           STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
controlplane   Ready    control-plane   23d   v1.33.2   172.30.1.2    <none>        Ubuntu 24.04.1 LTS   6.8.0-51-generic   containerd://1.7.27
node01         Ready    <none>          23d   v1.33.2   172.30.2.2    <none>        Ubuntu 24.04.1 LTS   6.8.0-51-generic   containerd://1.7.27

controlplane:~/deployments-edg$ curl http://172.30.1.2:30080/httpbin/get
{
  "args": {}, 
  "headers": {
    "Accept": "*/*", 
    "Host": "172.30.1.2:30080", 
    "User-Agent": "curl/8.5.0", 
    "X-Envoy-Expected-Rq-Timeout-Ms": "15000", 
    "X-Envoy-Original-Path": "/httpbin/get"
  }, 
  "origin": "192.168.1.8", 
  "url": "http://172.30.1.2:30080/get"
}

curl http://<node-ip>:30080/nginx/

#check envoy admin
kubectl port-forward deployment/envoy 9901:9901
curl http://localhost:9901/clusters
curl http://localhost:9901/listeners

#Access logs
kubectl logs -l app=envoy -f

#Simulating API Gateway → Envoy → Backend
#We can just deploy a dummy Nginx/Ingress 
or even another Envoy acting as API Gateway, and forward traffic into your Envoy service.

Refer and use: gateway-deployment.yaml

controlplane:~$ kubectl apply -f gateway-deployment.yaml 
deployment.apps/apigw created

controlplane:~$ kubectl get pods          
NAME                       READY   STATUS    RESTARTS   AGE
apigw-6cb7cd4dd7-qhss5     1/1     Running   0          9s
envoy-8f758f8b5-s7sq2      1/1     Running   0          5m58s
httpbin-56cc78c99f-666tz   1/1     Running   0          5m59s
nginx-86c57bc6b8-dg2cl     1/1     Running   0          5m59s

controlplane:~$ kubectl exec -it apigw-6cb7cd4dd7-qhss5 -- sh
~ $ curl http://envoy:10000/httpbin/get
{
  "args": {}, 
  "headers": {
    "Accept": "*/*", 
    "Host": "envoy:10000", 
    "User-Agent": "curl/8.16.0", 
    "X-Envoy-Expected-Rq-Timeout-Ms": "15000", 
    "X-Envoy-Original-Path": "/httpbin/get"
  }, 
  "origin": "192.168.1.6", 
  "url": "http://envoy:10000/get"
}

~ $ curl http://envoy:10000/nginx
<!DOCTYPE html>
<html>
<head>

#Using K6
k6 is an open-source load testing tool from Grafana Labs.
It’s designed for API, microservices, and web app testing — 
great for simulating real traffic patterns to your Envoy edge proxy.

--Can be run locally, in CI/CD pipelines, or inside Kubernetes.
--Exports results to Grafana, Prometheus, InfluxDB, JSON, etc.

Refer: k6-job.yaml,k6-configmap.yaml
kubectl apply -f k6-configmap.yaml
kubectl apply -f k6-job.yaml


controlplane:~$ kubectl logs -l job-name=k6-test -f

    NETWORK
    data_received..................: 202 kB 6.7 kB/s
    data_sent......................: 23 kB  743 B/s

running (0m30.3s), 0/5 VUs, 150 complete and 0 interrupted iterations
default ✓ [ 100% ] 5 VUs  30s

What does this mean?
running (0m30.3s), 0/5 VUs → the test ran for 30 seconds with 5 Virtual Users (VUs), and now all of 
them have finished.
150 complete and 0 interrupted iterations → your 5 users executed a total of 150 requests; 
none were interrupted or failed.
default [ 100% ] → all checks passed (status 200 from /httpbin and /nginx).
data_received / data_sent → shows total network traffic generated by the test.

[Optional]
--We can Add logging , rate limit flters to final deployment
